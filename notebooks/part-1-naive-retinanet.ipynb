{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Train a RetinaNet to Detect ElectroMagnetic Signals\n",
    "\n",
    "**Author:** [lukewood](https://lukewood.xyz), Kevin Anderson, Peter Gerstoft<br>\n",
    "**Date created:** 2022/08/16<br>\n",
    "**Last modified:** 2022/08/16<br>\n",
    "**Description:** Train ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO provide an overview of em-loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import keras_cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from absl import flags\n",
    "from keras_cv import bounding_box\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks as callbacks_lib\n",
    "from tensorflow.keras import optimizers\n",
    "from luketils import artifacts\n",
    "import em_loader\n",
    "import wandb\n",
    "from luketils import visualization\n",
    "\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "\n",
    "ground_truth_mapping = [\n",
    "    \"Ground Truth\",\n",
    "]\n",
    "ground_truth_mapping = dict(zip(range(len(ground_truth_mapping)), ground_truth_mapping))\n",
    "\n",
    "prediction_mapping = [\n",
    "    \"Prediction\",\n",
    "]\n",
    "prediction_mapping = dict(zip(range(len(prediction_mapping)), prediction_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "artifacts_dir = 'artifacts/naive/'\n",
    "artifacts.set_base(artifacts_dir)\n",
    "os.makedirs(artifacts_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Great!  Our data is now loaded into the format\n",
    "`{\"images\": images, \"bounding_boxes\": bounding_boxes}`.  This format is supported in all\n",
    "KerasCV preprocessing components.\n",
    "\n",
    "Lets load some data and verify that our data looks as we expect it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "dataset, dataset_info = em_loader.load(\n",
    "    split=\"train\",\n",
    "    bounding_box_format=\"xywh\",\n",
    "    batch_size=9,\n",
    "    version=2,\n",
    ")\n",
    "\n",
    "\n",
    "example = next(iter(dataset))\n",
    "images, boxes = example[\"images\"], example[\"bounding_boxes\"]\n",
    "\n",
    "plot_fn = functools.partial(visualization.plot_bounding_box_gallery, \n",
    "    images=images,\n",
    "    value_range=(0, 255),\n",
    "    bounding_box_format=\"xywh\",\n",
    "    y_true=boxes,\n",
    "    scale=2,\n",
    "    rows=3,\n",
    "    cols=3,\n",
    "    thickness=2,\n",
    "    font_scale=1,\n",
    "    class_mapping=ground_truth_mapping,\n",
    ")\n",
    "    \n",
    "plot_fn(path=f\"{artifacts_dir}/ground-truth.png\")\n",
    "plot_fn(show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Looks like everything is structured as expected.  Now we can move on to constructing our\n",
    "data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# train_ds is batched as a (images, bounding_boxes) tuple\n",
    "# bounding_boxes are ragged\n",
    "train_ds, train_dataset_info = em_loader.load(\n",
    "    bounding_box_format=\"xywh\", split=\"train\", batch_size=batch_size, version=2\n",
    ")\n",
    "val_ds, val_dataset_info = em_loader.load(\n",
    "    bounding_box_format=\"xywh\", split=\"val\", batch_size=batch_size, version=2\n",
    ")\n",
    "\n",
    "\n",
    "def unpackage_dict(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(unpackage_dict, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(unpackage_dict, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Our data pipeline is now complete.  We can now move on to model creation and training.\n",
    "\n",
    "## Model creation\n",
    "\n",
    "We'll use the KerasCV API to construct a RetinaNet model.  In this tutorial we use\n",
    "a pretrained ResNet50 backbone using weights.  In order to perform fine-tuning, we\n",
    "freeze the backbone before training.  When `include_rescaling=True` is set, inputs to\n",
    "the model are expected to be in the range `[0, 255]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.RetinaNet(\n",
    "    classes=1,\n",
    "    bounding_box_format=\"xywh\",\n",
    "    backbone=\"resnet50\",\n",
    "    backbone_weights=\"imagenet\",\n",
    "    include_rescaling=True,\n",
    "    evaluate_train_time_metrics=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(global_clipnorm=10.0)\n",
    "metrics = [\n",
    "    keras_cv.metrics.COCOMeanAveragePrecision(\n",
    "        class_ids=range(1),\n",
    "        bounding_box_format=\"xywh\",\n",
    "        name=\"MaP\",\n",
    "    ),\n",
    "    keras_cv.metrics.COCORecall(\n",
    "        class_ids=range(1),\n",
    "        bounding_box_format=\"xywh\",\n",
    "        max_detections=100,\n",
    "        name=\"Recall\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    classification_loss=keras_cv.losses.FocalLoss(from_logits=True, reduction=\"none\"),\n",
    "    box_loss=keras_cv.losses.SmoothL1Loss(l1_cutoff=1.0, reduction=\"none\"),\n",
    "    optimizer=optimizer,\n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "All that is left to do is construct some callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    callbacks_lib.TensorBoard(log_dir=\"logs\"),\n",
    "    callbacks_lib.ReduceLROnPlateau(patience=7),\n",
    "    keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "And run `model.fit()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds.take(20),\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "First, lets plot our learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join(metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = {\n",
    "    'Train': metrics['loss'],\n",
    "    'Validation': metrics['val_loss'],\n",
    "}\n",
    "\n",
    "plot_fn = functools.partial(visualization.line_plot, data=metrics_to_plot, title='Loss', xlabel='Epochs', ylabel='Loss', transparent=True)\n",
    "plot_fn(path=f'{artifacts_dir}/loss.png')\n",
    "plot_fn(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = {\n",
    "    'Mean Average Precision': metrics['val_MaP'],\n",
    "}\n",
    "\n",
    "plot_fn = functools.partial(visualization.line_plot, data=metrics_to_plot, title='Mean Average Precision', xlabel='Epochs', ylabel='Mean Average Precision')\n",
    "plot_fn(path=f'{artifacts_dir}/MaP.png')\n",
    "plot_fn(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = {\n",
    "    'Recall': metrics['val_Recall'],\n",
    "}\n",
    "\n",
    "plot_fn = functools.partial(visualization.line_plot, data=metrics_to_plot, title='Recall', xlabel='Epochs', ylabel='Recall')\n",
    "plot_fn(path=f'{artifacts_dir}/Recall.png')\n",
    "plot_fn(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = {\n",
    "    'Mean Average Precision': metrics['val_MaP'],\n",
    "    'Recall': metrics['val_Recall'],\n",
    "}\n",
    "\n",
    "plot_fn = functools.partial(visualization.line_plot, data=metrics_to_plot, title='COCO Metrics', xlabel='Epochs')\n",
    "plot_fn(path=f'{artifacts_dir}/COCO_Metrics.png')\n",
    "plot_fn(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = {\n",
    "    'Train': metrics['box_loss'],\n",
    "    'Validation': metrics['val_box_loss'],\n",
    "}\n",
    "\n",
    "plot_fn = functools.partial(visualization.line_plot, data=metrics_to_plot, title='Box Loss', xlabel='Epochs', ylabel='Box Loss')\n",
    "plot_fn(path=f'{artifacts_dir}/box_loss.png')\n",
    "plot_fn(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = {\n",
    "    'Train': metrics['classification_loss'],\n",
    "    'Validation': metrics['val_classification_loss'],\n",
    "}\n",
    "\n",
    "plot_fn = functools.partial(visualization.line_plot, data=metrics_to_plot, title='Classification Loss', xlabel='Epochs', ylabel='Classification Loss')\n",
    "plot_fn(path=f'{artifacts_dir}/classification_loss.png')\n",
    "plot_fn(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_plot = {\n",
    "    'Train Box Loss': metrics['box_loss'],\n",
    "    'Validation Box Loss': metrics['val_box_loss'],\n",
    "    'Train Classification Loss': metrics['classification_loss'],\n",
    "    'Validation Classification Loss': metrics['val_classification_loss'],\n",
    "}\n",
    "\n",
    "plot_fn = functools.partial(visualization.line_plot, data=metrics_to_plot, title='All Losses', xlabel='Epochs', ylabel='Box Loss')\n",
    "plot_fn(path=f'{artifacts_dir}/all_losses.png')\n",
    "plot_fn(show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(val_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINAL METRICS:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets write our metrics to our artifact directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{artifacts_dir}/metrics/', exist_ok=True)\n",
    "for metric in metrics:\n",
    "    with open(f\"{artifacts_dir}/metrics/{metric}.txt\", \"w\") as f:\n",
    "        f.write(str(round(metrics[metric], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, our metrics look pretty reasonable!  \n",
    "\n",
    "Very low loss, but our MaP and Recall are not that great.  For perspective, in PascalVOC you can expect a MaP of 0.35 in a state of the art workflow - but the loss converges at 2.0 instead of 0.001.  So all in all, we either have an overfitting problem or something else...\n",
    "\n",
    "For further investigation, lets visualize our detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def visualize_detections(model, split=\"train\"):\n",
    "    train_ds, val_dataset_info = em_loader.load(\n",
    "        bounding_box_format=\"xywh\", split=split, batch_size=9\n",
    "    )\n",
    "    train_ds = train_ds.map(unpackage_dict, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    images, y_true = next(iter(train_ds.take(1)))\n",
    "    y_pred = model.predict(images)\n",
    "    \n",
    "    plot_fn = functools.partial(\n",
    "        visualization.plot_bounding_box_gallery,\n",
    "        images,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format='xywh',\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        scale=2,\n",
    "        rows=3,\n",
    "        cols=3,\n",
    "        thickness=2,\n",
    "        font_scale=1,\n",
    "        legend=True,\n",
    "    )\n",
    "    plot_fn(\n",
    "        show=True,\n",
    "    )\n",
    "    plot_fn(\n",
    "        path=f\"{artifacts_dir}/{split}.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_detections(model, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_detections(model, split=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh!  Looks like something is going wrong!  It seems that we are not catching any of the small-skinny, or oblong bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "While the loss converges, we are not able to effectively detect signals in our spectograms.\n",
    "In part 2, we will dive into why we can't detect the signals and begin solving the issue.\n",
    "That concludes part one of our notebooks.  To find out why, see part-2 of our notebooks!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
